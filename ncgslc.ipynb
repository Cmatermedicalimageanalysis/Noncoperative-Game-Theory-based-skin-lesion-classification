{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6128847,"sourceType":"datasetVersion","datasetId":3513799}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets, models as torchvision_models\nfrom torch.utils.data import DataLoader, random_split\nfrom tqdm.auto import tqdm\nimport numpy as np\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.models import resnet101, ResNet101_Weights\nfrom torchvision.models import resnet50, ResNet50_Weights\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install timm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torchvision.models import resnet50, resnet101\nimport numpy as np\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nfrom torchvision.models.resnet import resnet101, ResNet101_Weights\nfrom torchvision.datasets import ImageFolder","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define SelfAttention and Custom models\nclass SelfAttention(nn.Module):\n    def __init__(self, embed_size):\n        super(SelfAttention, self).__init__()\n        self.embed_size = embed_size\n        self.query = nn.Linear(embed_size, embed_size)\n        self.key = nn.Linear(embed_size, embed_size)\n        self.value = nn.Linear(embed_size, embed_size)\n\n    def forward(self, x):\n        Q = self.query(x)\n        K = self.key(x)\n        V = self.value(x)\n        attention_weights = torch.softmax(torch.bmm(Q, K.permute(0, 2, 1)) / (self.embed_size ** 0.5), dim=-1)\n        out = torch.bmm(attention_weights, V)\n        return out.squeeze(1)\n\nclass CustomResNet50(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomResNet50, self).__init__()\n        original_model = resnet50(weights=ResNet50_Weights.DEFAULT)\n        self.features = nn.Sequential(*list(original_model.children())[:-2])\n        self.attention = SelfAttention(embed_size=2048)\n        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Linear(2048, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.attention(x.unsqueeze(1))\n        x = self.classifier(x)\n        return x\n\nclass CustomResNet101(nn.Module):\n    def __init__(self, num_classes):\n        super(CustomResNet101, self).__init__()\n        original_model = resnet101(weights=ResNet101_Weights.DEFAULT)\n        self.features = nn.Sequential(*list(original_model.children())[:-2])\n        self.attention = SelfAttention(embed_size=2048)\n        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Linear(2048, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.pool(x)\n        x = x.view(x.size(0), -1)\n        x = self.attention(x.unsqueeze(1))\n        x = self.classifier(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correct data transformations\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Lambda(lambda x: x.convert('RGB')),\n        transforms.Resize((299, 299)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Lambda(lambda x: x.convert('RGB')),\n        transforms.Resize((299, 299)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n\n\n# Load image data\ntrain_dir = '/kaggle/input/ham10000-data/HAM10000_DATA/train_dir'\n# val_dir = '/kaggle/input/ham10000-data/HAM10000_DATA/test_dir'\n\n#Use train_dir to create both train and val datasets since dataset only has train and test data\nfull_dataset = ImageFolder(train_dir,transform=None)\ntrain_ratio = 0.8\ntrain_size = int(train_ratio * len(full_dataset))\nval_size = len(full_dataset) - train_size\ntrain_dataset,val_dataset = random_split(full_dataset,[train_size,val_size])\n\n# Apply different transforms to train and val datasets by overriding the transform attribute\ntrain_dataset.dataset.transform = data_transforms['train']\nval_dataset.dataset.transform = data_transforms['val']\n\n# image_datasets = {\n#     'train': ImageFolder(train_dir, transform=data_transforms['train']),\n#     'val': ImageFolder(val_dir, transform=data_transforms['val']),\n# }\n\n# Create DataLoader objects\ndataloaders = {\n    'train': DataLoader(train_dataset, batch_size=4, shuffle=True),\n    'val': DataLoader(val_dataset, batch_size=4, shuffle=False),\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_classes = 7\ncriterion = nn.CrossEntropyLoss()\n\n# Initialize models and optimizers\ncustom_resnet50 = CustomResNet50(num_classes).to(device)\ncustom_resnet101 = CustomResNet101(num_classes).to(device)\nmodels = {\n    'CustomResNet50': {'model': custom_resnet50, 'optimizer': optim.Adam(custom_resnet50.parameters(), lr=0.0001)},\n    'CustomResNet101': {'model': custom_resnet101, 'optimizer': optim.Adam(custom_resnet101.parameters(), lr=0.0001)}\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Training and evaluation functions as previously provided\ndef train_one_epoch(model, dataloader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    running_corrects = 0\n\n    for inputs, labels in tqdm(dataloader, desc=\"Training\", leave=False):\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        _, preds = torch.max(outputs, 1)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * inputs.size(0)\n        running_corrects += torch.sum(preds == labels.data)\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n    return epoch_loss, epoch_acc\n\ndef evaluate_model(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n\n    with torch.no_grad():\n        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            _, preds = torch.max(outputs, 1)\n\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n    return epoch_loss, epoch_acc\n\ndef compete_until_equilibrium(models, dataloaders, criterion, device, num_epochs=25, threshold=0.001):\n    std_devs = []\n    best_std = float(\"inf\")\n    performance_metrics = {name: {'last_val_loss': float('inf'), 'best_val_acc': 0} for name in models.keys()}\n\n    for epoch in range(num_epochs):\n        print(f\"\\nEpoch {epoch+1}/{num_epochs}\\n{'=' * 60}\")\n        model_metrics = {}\n\n        for name, model_info in models.items():\n            model = model_info['model']\n            optimizer = model_info['optimizer']\n\n            train_loss, train_acc = train_one_epoch(model, dataloaders['train'], criterion, optimizer, device)\n            val_loss, val_acc = evaluate_model(model, dataloaders['val'], criterion, device)\n            print(f\"{name} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n            model_metrics[name] = {'val_loss': val_loss, 'val_acc': val_acc}\n\n        losses_list = [metrics['val_loss'] for metrics in model_metrics.values()]\n        std_dev = np.std(losses_list)\n        std_devs.append(std_dev)\n        print(f\"Standard Deviation of Validation Losses: {std_dev:.4f}\")\n\n        if std_dev < best_std:\n            best_std = std_dev\n            for name, model_info in models.items():\n                if std_dev < performance_metrics[name]['last_val_loss'] or model_metrics[name]['val_acc'] > performance_metrics[name]['best_val_acc']:\n                    torch.save(model_info['model'].state_dict(), f\"/kaggle/working/{name}.pth\")\n                    print(f'===> {name} model saved based on new std or val acc improvement')\n                    performance_metrics[name]['best_val_acc'] = model_metrics[name]['val_acc']\n\n        sorted_models = sorted(model_metrics.keys(), key=lambda x: (model_metrics[x]['val_loss'], -model_metrics[x]['val_acc']))\n        for rank, name in enumerate(sorted_models):\n            improvement = performance_metrics[name]['last_val_loss'] - model_metrics[name]['val_loss']\n            adjust_factor = max(0.9, 1 - 0.05 * improvement)\n            new_lr = models[name]['optimizer'].param_groups[0]['lr'] * adjust_factor\n            new_lr = max(new_lr, 1e-6)\n            models[name]['optimizer'].param_groups[0]['lr'] = new_lr\n            performance_metrics[name]['last_val_loss'] = model_metrics[name]['val_loss']\n            print(f\"Adjusted {name}'s learning rate to {new_lr:.2e}\")\n\n        if std_dev < threshold:\n            print(\"Equilibrium reached among models.\")\n            break\n\n    return std_devs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"std_devs = compete_until_equilibrium(models, dataloaders, criterion, device, num_epochs=50, threshold=0.01)\n\nplt.plot(range(1, len(std_devs) + 1), std_devs, marker='o')\nplt.xlabel('Epochs')\nplt.ylabel('Standard Deviation of Validation Losses')\nplt.title('Standard Deviation vs Epochs')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import confusion_matrix, classification_report\n# Initialize models\nmodel1 = CustomResNet50(4)\nmodel2 = CustomResNet101(4)\n\n# Load weights\nmodel1.load_state_dict(torch.load('/kaggle/working/CustomResNet50.pth'))\nmodel2.load_state_dict(torch.load('/kaggle/working/CustomResNet101.pth'))\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel1.to(device)\nmodel2.to(device)\n\n# Set models to evaluation mode\nmodel1.eval()\nmodel2.eval()\n\n# Validation dataloader\nval_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_dataset = datasets.ImageFolder('/kaggle/input/ham10000-data/HAM10000_DATA/test_dir', transform=val_transforms)\nval_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n\n# Function to get predictions and labels\ndef get_predictions_and_labels(model, dataloader, device):\n    all_outputs = []\n    all_labels = []\n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n            all_outputs.append(probabilities)\n            all_labels.append(labels)\n    return torch.cat(all_outputs, dim=0), torch.cat(all_labels, dim=0)\n\n# Load models, set device, dataloaders etc. from previous setup\n\n# Get predictions and labels from both models\npredictions1, labels = get_predictions_and_labels(model1, val_loader, device)\npredictions2, _ = get_predictions_and_labels(model2, val_loader, device)\n\n# Ensemble predictions (simple average of softmax outputs)\nensemble_predictions = (predictions1 + predictions2) / 2\n\n# Determine final predicted classes\nfinal_predictions = torch.argmax(ensemble_predictions, dim=1).cpu().numpy()\nlabels = labels.cpu().numpy()\n\n# Calculate accuracy\naccuracy = (final_predictions == labels).mean()\nprint(f\"Ensemble accuracy on validation data: {accuracy:.4f}\")\n\n# Compute confusion matrix\nconf_matrix = confusion_matrix(labels, final_predictions)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)\n\n# Print classification report\nclass_report = classification_report(labels, final_predictions)\nprint(\"Classification Report:\")\nprint(class_report)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Validation dataloader\ntest_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntest_dataset = datasets.ImageFolder('/kaggle/input/ham10000-data/HAM10000_DATA/test_dir', transform=test_transforms)\ntest_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_transforms = {\n    'test': transforms.Compose([\n        transforms.Lambda(lambda x: x.convert('RGB')),\n        transforms.Resize((299, 299)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load image data\ntest_dir = '/kaggle/input/ham10000-data/HAM10000_DATA/test_dir'\nimage_datasets = {\n    'test': ImageFolder(test_dir, transform=data_transforms['test'])\n}\n\n# Create DataLoader objects\ndataloaders = {\n    'test': DataLoader(image_datasets['test'], batch_size=4, shuffle=False)\n    \n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model_and_collect_outputs(model, dataloader, device):\n    model.eval()\n    total_outputs = []\n    total_labels = []\n\n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            total_outputs.append(outputs.cpu())\n            total_labels.append(labels.cpu())\n\n    total_outputs = torch.cat(total_outputs, dim=0)\n    total_labels = torch.cat(total_labels, dim=0)\n    return total_outputs, total_labels\n\n# Collect outputs and labels\noutputs_resnet50, labels = evaluate_model_and_collect_outputs(models['CustomResNet50']['model'], dataloaders['test'], device)\noutputs_resnet101, _ = evaluate_model_and_collect_outputs(models['CustomResNet101']['model'], dataloaders['test'], device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Compute accuracies for individual models\n_, preds_resnet50 = torch.max(outputs_resnet50, 1)\n_, preds_resnet101 = torch.max(outputs_resnet101, 1)\nacc_resnet50 = accuracy_score(labels.numpy(), preds_resnet50.numpy())\nacc_resnet101 = accuracy_score(labels.numpy(), preds_resnet101.numpy())\n\n# Compute ensemble accuracy\nensemble_outputs = (outputs_resnet50 + outputs_resnet101) / 2\n_, ensemble_preds = torch.max(ensemble_outputs, 1)\nensemble_acc = accuracy_score(labels.numpy(), ensemble_preds.numpy())\n\n# Calculate Shapley values\nphi_resnet50 = (acc_resnet50 + ensemble_acc - acc_resnet101) / 2\nphi_resnet101 = (acc_resnet101 + ensemble_acc - acc_resnet50) / 2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"weighted_ensemble_outputs = (phi_resnet50 * outputs_resnet50 + phi_resnet101 * outputs_resnet101) / (phi_resnet50 + phi_resnet101)\n_, weighted_ensemble_preds = torch.max(weighted_ensemble_outputs, 1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(labels.numpy(), weighted_ensemble_preds.numpy())\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot()\nplt.title('Confusion Matrix for Weighted Ensemble')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Generate the classification report\nreport = classification_report(labels.numpy(), weighted_ensemble_preds.numpy(), target_names=['akiec', 'bcc', 'bkl','df', 'mel', 'nv', 'vasc'])\n\nprint(\"Classification Report for Weighted Ensemble:\")\nprint(report)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r model_files.zip /kaggle/working/CustomResNet101.pth","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r model_files.zip /kaggle/working/CustomResNet50.pth","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nsoftmax = torch.nn.Softmax(dim=1)\nprobabilities = softmax(weighted_ensemble_outputs).numpy()[:, 1]  # Probabilities for class 1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(labels.numpy().shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cd /kaggle/working\nfrom IPython.display import FileLink\nFileLink(r'model_files.zip')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}